{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b7fb17",
   "metadata": {},
   "source": [
    "# Learning Rate Sweep with Early Stopping\n",
    "\n",
    "This notebook demonstrates how to use `torch-batteries` to perform a learning rate sweep with eager early stopping.\n",
    "\n",
    "**Research Question**: What learning rate achieves the fastest convergence with early stopping?\n",
    "\n",
    "**Experiment Design**:\n",
    "- Train models with different learning rates (1e-4, 5e-4, 1e-3, 5e-3, 1e-2)\n",
    "- Use aggressive early stopping (patience=3) to quickly identify poor LRs\n",
    "- Track all metrics automatically to Weights & Biases\n",
    "- Compare convergence speed and final accuracy\n",
    "\n",
    "**What gets tracked**:\n",
    "- Training and validation metrics (loss, accuracy)\n",
    "- Hyperparameters (learning rate, batch size, patience)\n",
    "- When training stopped\n",
    "- Whether early stopping was triggered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39f9b4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b781fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (only when running on Google Colab)\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    !pip install torch-batteries[wandb]\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b78000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch-batteries version: 0.4.0\n",
      "PyTorch version: 2.9.1+cu128\n",
      "Is CUDA available?: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import wandb\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch_batteries\n",
    "from torch_batteries import Battery, Event, charge\n",
    "from torch_batteries.callbacks import EarlyStopping, ExperimentTrackingCallback\n",
    "from torch_batteries.tracking import WandbTracker, Run\n",
    "from torch_batteries.events.core import EventContext\n",
    "\n",
    "print(f\"torch-batteries version: {torch_batteries.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "print(f\"Is CUDA available?: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21eb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "W&B Settings:\n",
      "  Project: torch-batteries-integration\n",
      "  Entity: default\n"
     ]
    }
   ],
   "source": [
    "wandb_project_name = input(\"Enter your wandb project name (default: 'torch-batteries-integration'): \").strip() or \"torch-batteries-integration\"\n",
    "\n",
    "# Wandb entity (optional)\n",
    "wandb_entity = input(\"Enter your wandb entity (username/team) or press Enter to skip: \").strip() or None\n",
    "\n",
    "print(f\"\\nW&B Settings:\")\n",
    "print(f\"  Project: {wandb_project_name}\")\n",
    "print(f\"  Entity: {wandb_entity if wandb_entity else 'default'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad94197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d62644",
   "metadata": {},
   "source": [
    "## 1. Prepare Data\n",
    "\n",
    "Load MNIST dataset with train/validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100b3a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 54000\n",
      "Validation samples: 6000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "full_train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_train_dataset, [0.9, 0.1])\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcddb10",
   "metadata": {},
   "source": [
    "## 2. Define the Model\n",
    "\n",
    "Simple CNN for MNIST classification with training and validation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26da32c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 19146\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    @charge(Event.TRAIN_STEP)\n",
    "    def training_step(self, context: EventContext):\n",
    "        x, y = context[\"batch\"]\n",
    "        return F.cross_entropy(self(x), y)\n",
    "\n",
    "    @charge(Event.VALIDATION_STEP)\n",
    "    def validation_step(self, context: EventContext):\n",
    "        x, y = context[\"batch\"]\n",
    "        return F.cross_entropy(self(x), y)\n",
    "\n",
    "\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in MNISTNet().parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf7d8b",
   "metadata": {},
   "source": [
    "## 3. Define Base Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8b0aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Configuration:\n",
      "{'model': 'CNN',\n",
      " 'tags': ['lr-sweep', 'cnn', 'mnist'],\n",
      " 'dataset': 'MNIST',\n",
      " 'batch_size': 256,\n",
      " 'optimizer': 'Adam',\n",
      " 'max_epochs': 20,\n",
      " 'early_stopping_patience': 3,\n",
      " 'early_stopping_monitor': 'val_accuracy',\n",
      " 'early_stopping_min_delta': 0.1,\n",
      " 'learning_rate': None}\n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"model\": \"CNN\",\n",
    "    \"tags\": [\"lr-sweep\", \"cnn\", \"mnist\"],\n",
    "    \"dataset\": \"MNIST\",\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"max_epochs\": 20,\n",
    "    # Aggressive early stopping for quick experiments\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_monitor\": \"val_accuracy\",\n",
    "    \"early_stopping_min_delta\": 0.1,\n",
    "    \"learning_rate\": None,  # To be set per run\n",
    "}\n",
    "\n",
    "print(\"Base Configuration:\")\n",
    "pprint(BASE_CONFIG, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e1a377",
   "metadata": {},
   "source": [
    "## 4. Run Learning Rate Sweep\n",
    "\n",
    "Train models with different learning rates where each run will:\n",
    "1. Initialize a fresh model and a optimizer with a specific learning rate\n",
    "2. Set up experiment tracking\n",
    "3. Log all metrics to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1977a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    pred_labels = predictions.argmax(dim=1)\n",
    "    return (pred_labels == targets).float().mean().item()\n",
    "\n",
    "metrics = {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47048a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=1e-04\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260117_215241-2zogq6lv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/2zogq6lv' target=\"_blank\">lr-1e-04</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/2zogq6lv' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/2zogq6lv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▁▂▄▅▆▇▆▇▇▇▇▇▇▇▇███▇████████████████████</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train/loss</td><td>████▇▆▅▄▄▃▃▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▅▆▇▇███</td></tr><tr><td>val/epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>val/loss</td><td>█▄▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>7</td></tr><tr><td>total_steps</td><td>1688</td></tr><tr><td>train/accuracy</td><td>0.91667</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/loss</td><td>0.24786</td></tr><tr><td>val/accuracy</td><td>0.928</td></tr><tr><td>val/epoch</td><td>7</td></tr><tr><td>val/loss</td><td>0.24436</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-1e-04</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/2zogq6lv' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/2zogq6lv</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260117_215241-2zogq6lv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Epochs trained: 8\n",
      "  Learning rate: 1e-04\n",
      "  Final train loss: 0.2489\n",
      "  Final val loss: 0.2444\n",
      "  Final val accuracy: 0.9280\n",
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=5e-04\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260117_215628-fan4y8o1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/fan4y8o1' target=\"_blank\">lr-5e-04</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/fan4y8o1' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/fan4y8o1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▃▂▃▅▅▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇█▇▇███████▇█████</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▆▆▆▆▆████████████</td></tr><tr><td>train/loss</td><td>██▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▅▇█</td></tr><tr><td>val/epoch</td><td>▁▃▆█</td></tr><tr><td>val/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>3</td></tr><tr><td>total_steps</td><td>844</td></tr><tr><td>train/accuracy</td><td>0.9625</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/loss</td><td>0.14363</td></tr><tr><td>val/accuracy</td><td>0.947</td></tr><tr><td>val/epoch</td><td>3</td></tr><tr><td>val/loss</td><td>0.17037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-5e-04</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/fan4y8o1' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/fan4y8o1</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260117_215628-fan4y8o1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Epochs trained: 4\n",
      "  Learning rate: 5e-04\n",
      "  Final train loss: 0.1816\n",
      "  Final val loss: 0.1704\n",
      "  Final val accuracy: 0.9470\n",
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=1e-03\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260117_215820-t3gyonz4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/t3gyonz4' target=\"_blank\">lr-1e-03</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/t3gyonz4' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/t3gyonz4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▄▅▅▅▆█▇▇▇▇▇██▇▇▇██▇▇▇██▇███▇████▇██▇███</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆█████████████</td></tr><tr><td>train/loss</td><td>█▃▃▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▅▇█</td></tr><tr><td>val/epoch</td><td>▁▃▆█</td></tr><tr><td>val/loss</td><td>█▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>3</td></tr><tr><td>total_steps</td><td>844</td></tr><tr><td>train/accuracy</td><td>0.975</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/loss</td><td>0.10697</td></tr><tr><td>val/accuracy</td><td>0.95567</td></tr><tr><td>val/epoch</td><td>3</td></tr><tr><td>val/loss</td><td>0.14948</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-1e-03</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/t3gyonz4' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/t3gyonz4</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260117_215820-t3gyonz4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Epochs trained: 4\n",
      "  Learning rate: 1e-03\n",
      "  Final train loss: 0.1454\n",
      "  Final val loss: 0.1495\n",
      "  Final val accuracy: 0.9557\n",
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=5e-03\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260117_220021-e6zyjua1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/e6zyjua1' target=\"_blank\">lr-5e-03</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/e6zyjua1' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/e6zyjua1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▁▄▄▄▆▇▇▇███▇█▇█████████████████████████</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆██████████</td></tr><tr><td>train/loss</td><td>█▅▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▅▆█</td></tr><tr><td>val/epoch</td><td>▁▃▆█</td></tr><tr><td>val/loss</td><td>█▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>3</td></tr><tr><td>total_steps</td><td>844</td></tr><tr><td>train/accuracy</td><td>0.97083</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/loss</td><td>0.07237</td></tr><tr><td>val/accuracy</td><td>0.97583</td></tr><tr><td>val/epoch</td><td>3</td></tr><tr><td>val/loss</td><td>0.08107</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-5e-03</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/e6zyjua1' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/e6zyjua1</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260117_220021-e6zyjua1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Epochs trained: 4\n",
      "  Learning rate: 5e-03\n",
      "  Final train loss: 0.0920\n",
      "  Final val loss: 0.0811\n",
      "  Final val accuracy: 0.9758\n",
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=1e-02\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260117_220216-w9tjfhb6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/w9tjfhb6' target=\"_blank\">lr-1e-02</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/w9tjfhb6' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/w9tjfhb6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▃▆▇▇█▇▇█▇▇▇████████████████████████████</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆█████</td></tr><tr><td>train/loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▄██</td></tr><tr><td>val/epoch</td><td>▁▃▆█</td></tr><tr><td>val/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>3</td></tr><tr><td>total_steps</td><td>844</td></tr><tr><td>train/accuracy</td><td>0.97083</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/loss</td><td>0.13054</td></tr><tr><td>val/accuracy</td><td>0.965</td></tr><tr><td>val/epoch</td><td>3</td></tr><tr><td>val/loss</td><td>0.11028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-1e-02</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/w9tjfhb6' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/w9tjfhb6</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260117_220216-w9tjfhb6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Epochs trained: 4\n",
      "  Learning rate: 1e-02\n",
      "  Final train loss: 0.1133\n",
      "  Final val loss: 0.1103\n",
      "  Final val accuracy: 0.9650\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting run with learning_rate={lr:.0e}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    config = deepcopy(BASE_CONFIG)\n",
    "    config[\"learning_rate\"] = lr\n",
    "    \n",
    "    model = MNISTNet()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    run = Run(\n",
    "        name=f\"lr-{lr:.0e}\",\n",
    "        group=\"lr-sweep\",\n",
    "        description=\"Learning rate sweep with early stopping on MNIST dataset using a CNN model\",\n",
    "        config=config,\n",
    "        job_type=\"training\",\n",
    "    )\n",
    "    \n",
    "    tracker = WandbTracker(project=wandb_project_name, entity=wandb_entity)\n",
    "    \n",
    "    callbacks = [\n",
    "        ExperimentTrackingCallback(\n",
    "            tracker=tracker,\n",
    "            run=run,\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            stage=config[\"early_stopping_monitor\"].split(\"_\")[0],\n",
    "            metric=config[\"early_stopping_monitor\"].split(\"_\")[1],\n",
    "            patience=config[\"early_stopping_patience\"],\n",
    "            min_delta=config[\"early_stopping_min_delta\"],\n",
    "            mode=\"max\",\n",
    "            verbose=True,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    battery = Battery(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    result = battery.train(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=config[\"max_epochs\"],\n",
    "        verbose=0,  # We can see progress in W&B\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'train_loss': result[\"train_loss\"][-1],\n",
    "        'val_loss': result[\"val_loss\"][-1],\n",
    "        'val_accuracy': result[\"val_metrics\"]['accuracy'][-1],\n",
    "        'epochs_trained': len(result[\"train_loss\"]),\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nRun completed:\")\n",
    "    print(f\"  Epochs trained: {len(result['train_loss'])}\")\n",
    "    print(f\"  Learning rate: {lr:.0e}\")\n",
    "    print(f\"  Final train loss: {result['train_loss'][-1]:.4f}\")\n",
    "    print(f\"  Final val loss: {result['val_loss'][-1]:.4f}\")\n",
    "    print(f\"  Final val accuracy: {result['val_metrics']['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a37fb",
   "metadata": {},
   "source": [
    "## 5. Summary of Results\n",
    "\n",
    "Quick overview of all runs to identify the best learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d7598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LEARNING RATE SWEEP SUMMARY\n",
      "================================================================================\n",
      "LR           Val Loss     Val Acc      Epochs       Status\n",
      "--------------------------------------------------------------------------------\n",
      "1e-04        0.2444       0.9280       8            Early Stopped\n",
      "5e-04        0.1704       0.9470       4            Early Stopped\n",
      "1e-03        0.1495       0.9557       4            Early Stopped\n",
      "5e-03        0.0811       0.9758       4            Early Stopped\n",
      "1e-02        0.1103       0.9650       4            Early Stopped\n",
      "================================================================================\n",
      "\n",
      "Best learning rate: 5e-03\n",
      "Best validation accuracy: 0.9758\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEARNING RATE SWEEP SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'LR':<12} {'Val Loss':<12} {'Val Acc':<12} {'Epochs':<12} {'Status'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "best_lr = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for r in results:\n",
    "    status = \"Early Stopped\" if r['epochs_trained'] < BASE_CONFIG[\"max_epochs\"] else \"Completed\"\n",
    "    print(f\"{r['lr']:<12.0e} {r['val_loss']:<12.4f} {r['val_accuracy']:<12.4f} {r['epochs_trained']:<12} {status}\")\n",
    "    \n",
    "    if r['val_accuracy'] > best_accuracy:\n",
    "        best_accuracy = r['val_accuracy']\n",
    "        best_lr = r['lr']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest learning rate: {best_lr:.0e}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827df9cb",
   "metadata": {},
   "source": [
    "## 6. View Results in Weights & Biases\n",
    "\n",
    "After running the experiments, you can:\n",
    "\n",
    "1. **View the dashboard**: Go to your wandb project page\n",
    "2. **Compare runs**: See all grouped runs\n",
    "3. **Analyze metrics**: \n",
    "   - Training curves showing convergence speed\n",
    "   - Comparison of final accuracies across learning rates\n",
    "\n",
    "**Key insights to look for**:\n",
    "- Which learning rates converged quickly?\n",
    "- Which learning rates were stopped early due to poor performance?\n",
    "- Trade-off between convergence speed and final accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-batteries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
