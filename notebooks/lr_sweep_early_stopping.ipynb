{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b7fb17",
   "metadata": {},
   "source": [
    "# Learning Rate Sweep with Early Stopping\n",
    "\n",
    "This notebook demonstrates how to use `torch-batteries` to perform a learning rate sweep with eager early stopping.\n",
    "\n",
    "**Research Question**: What learning rate achieves the fastest convergence with early stopping?\n",
    "\n",
    "**Experiment Design**:\n",
    "- Train models with different learning rates (1e-4, 5e-4, 1e-3, 5e-3, 1e-2)\n",
    "- Use aggressive early stopping (patience=3) to quickly identify poor LRs\n",
    "- Track all metrics automatically to Weights & Biases\n",
    "- Compare convergence speed and final accuracy\n",
    "\n",
    "**What gets tracked**:\n",
    "- Training and validation metrics (loss, accuracy)\n",
    "- Hyperparameters (learning rate, batch size, patience)\n",
    "- When training stopped\n",
    "- Whether early stopping was triggered\n",
    "- Model artifacts (checkpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39f9b4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b781fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# !pip install torch-batteries wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b78000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available?: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import wandb\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from torch_batteries import Battery, Event, charge\n",
    "from torch_batteries.callbacks import EarlyStopping, ExperimentTrackingCallback\n",
    "from torch_batteries.tracking import WandbTracker, Project, Experiment, Run\n",
    "from torch_batteries.events.core import EventContext\n",
    "\n",
    "print(f\"Is CUDA available?: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21eb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "  Project: torch-batteries-integration\n",
      "  Entity: default\n"
     ]
    }
   ],
   "source": [
    "project_name = input(\"Enter your wandb project name (default: 'torch-batteries-integration'): \").strip() or \"torch-batteries-integration\"\n",
    "\n",
    "# Wandb entity (optional)\n",
    "wandb_entity = input(\"Enter your wandb entity (username/team) or press Enter to skip: \").strip() or None\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Project: {project_name}\")\n",
    "print(f\"  Entity: {wandb_entity if wandb_entity else 'default'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad94197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb27b2",
   "metadata": {},
   "source": [
    "## 1. Define the Model\n",
    "\n",
    "Simple CNN for MNIST classification with training and validation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811e07d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 19146\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    @charge(Event.TRAIN_STEP)\n",
    "    def training_step(self, context: EventContext):\n",
    "        x, y = context[\"batch\"]\n",
    "        return F.cross_entropy(self(x), y)\n",
    "\n",
    "    @charge(Event.VALIDATION_STEP)\n",
    "    def validation_step(self, context: EventContext):\n",
    "        x, y = context[\"batch\"]\n",
    "        return F.cross_entropy(self(x), y)\n",
    "\n",
    "\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in MNISTNet().parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d62644",
   "metadata": {},
   "source": [
    "## 2. Prepare Data\n",
    "\n",
    "Load MNIST dataset with train/validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b3a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Validation samples: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf7d8b",
   "metadata": {},
   "source": [
    "## 3. Define Experiment Configuration\n",
    "\n",
    "Set up the experiment tracking structure:\n",
    "- **Project**: \"lr-sweep-research\" (top-level container)\n",
    "- **Experiment**: \"lr-sweep-eager-es\" (this specific investigation)\n",
    "- **Runs**: Multiple runs with different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: torch-batteries-integration\n",
      "Experiment: lr-sweep-eager-es\n",
      "Base config: {'model': 'CNN', 'dataset': 'MNIST', 'batch_size': 256, 'optimizer': 'Adam', 'max_epochs': 20, 'early_stopping_patience': 3}\n"
     ]
    }
   ],
   "source": [
    "project = Project(\n",
    "    name=project_name,\n",
    "    description=\"Learning rate sweep research on MNIST classification\"\n",
    ")\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=\"lr-sweep-eager-es\",\n",
    "    description=\"Finding optimal learning rate with aggressive early stopping (patience=3)\",\n",
    "    base_config={\n",
    "        \"model\": \"CNN\",\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"max_epochs\": 20,\n",
    "        \"early_stopping_patience\": 3,\n",
    "    },\n",
    "    tags=[\"lr-sweep\", \"early-stopping\", \"cnn\", \"mnist\"]\n",
    ")\n",
    "\n",
    "print(f\"Project: {project.name}\")\n",
    "print(f\"Experiment: {experiment.name}\")\n",
    "print(f\"Base config: {experiment.base_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e1a377",
   "metadata": {},
   "source": [
    "## 4. Run Learning Rate Sweep\n",
    "\n",
    "Train models with different learning rates. Each run:\n",
    "1. Initialize a fresh model with a specific learning rate\n",
    "2. Set up experiment tracking\n",
    "3. Train with aggressive early stopping (patience=3, delta=0.1)\n",
    "4. Log all metrics to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1977a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\n",
    "\n",
    "max_epochs = 20\n",
    "patience = 3  # Aggressive early stopping\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    pred_labels = predictions.argmax(dim=1)\n",
    "    return (pred_labels == targets).float().mean().item()\n",
    "\n",
    "metrics = {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47048a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=1e-04\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260112_131926-odjf0k80</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/odjf0k80' target=\"_blank\">lr-1e-04</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/odjf0k80' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/odjf0k80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 235/235 [00:26<00:00,  8.72it/s, Loss=2.0636, Accuracy=0.4098]\n",
      "Epoch 1/20 [Validation]: 100%|██████████| 40/40 [00:02<00:00, 13.51it/s, Loss=1.5402, Accuracy=0.6696]\n",
      "Epoch 2/20 [Train]: 100%|██████████| 235/235 [00:26<00:00,  8.95it/s, Loss=1.0243, Accuracy=0.7623]\n",
      "Epoch 2/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 12.23it/s, Loss=0.6638, Accuracy=0.8298]\n",
      "Epoch 3/20 [Train]: 100%|██████████| 235/235 [00:27<00:00,  8.50it/s, Loss=0.5452, Accuracy=0.8531]\n",
      "Epoch 3/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 12.46it/s, Loss=0.4236, Accuracy=0.8876]\n",
      "Epoch 4/20 [Train]: 100%|██████████| 235/235 [00:29<00:00,  8.09it/s, Loss=0.3910, Accuracy=0.8910]\n",
      "Epoch 4/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 11.68it/s, Loss=0.3236, Accuracy=0.9115]\n",
      "Epoch 5/20 [Train]: 100%|██████████| 235/235 [00:30<00:00,  7.74it/s, Loss=0.3154, Accuracy=0.9110]\n",
      "Epoch 5/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 12.59it/s, Loss=0.2636, Accuracy=0.9281]\n",
      "Epoch 6/20 [Train]: 100%|██████████| 235/235 [00:28<00:00,  8.34it/s, Loss=0.2708, Accuracy=0.9240]\n",
      "Epoch 6/20 [Validation]: 100%|██████████| 40/40 [00:02<00:00, 14.29it/s, Loss=0.2292, Accuracy=0.9373]\n",
      "Epoch 7/20 [Train]: 100%|██████████| 235/235 [00:25<00:00,  9.35it/s, Loss=0.2416, Accuracy=0.9331]\n",
      "Epoch 7/20 [Validation]: 100%|██████████| 40/40 [00:02<00:00, 14.18it/s, Loss=0.2052, Accuracy=0.9430]\n",
      "Epoch 8/20 [Train]: 100%|██████████| 235/235 [00:28<00:00,  8.15it/s, Loss=0.2202, Accuracy=0.9381]\n",
      "Epoch 8/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 10.63it/s, Loss=0.1891, Accuracy=0.9472]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▁▄▆▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>train/loss</td><td>█████▆▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▅▆▇████</td></tr><tr><td>val/loss</td><td>█▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>7</td></tr><tr><td>total_steps</td><td>1880</td></tr><tr><td>train/accuracy</td><td>0.97917</td></tr><tr><td>train/loss</td><td>0.08572</td></tr><tr><td>val/accuracy</td><td>0.9472</td></tr><tr><td>val/loss</td><td>0.18911</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-1e-04</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/odjf0k80' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/odjf0k80</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260112_131926-odjf0k80/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Learning rate: 1e-04\n",
      "  Final train loss: 0.2202\n",
      "  Final val loss: 0.1891\n",
      "  Final val accuracy: 0.9472\n",
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=5e-04\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260112_132337-mofct3j7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/mofct3j7' target=\"_blank\">lr-5e-04</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/mofct3j7' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/mofct3j7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 235/235 [00:28<00:00,  8.27it/s, Loss=0.9582, Accuracy=0.7451]\n",
      "Epoch 1/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 12.05it/s, Loss=0.2942, Accuracy=0.9157]\n",
      "Epoch 2/20 [Train]: 100%|██████████| 235/235 [00:27<00:00,  8.50it/s, Loss=0.2515, Accuracy=0.9299]\n",
      "Epoch 2/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 11.91it/s, Loss=0.1740, Accuracy=0.9516]\n",
      "Epoch 3/20 [Train]: 100%|██████████| 235/235 [00:28<00:00,  8.24it/s, Loss=0.1805, Accuracy=0.9484]\n",
      "Epoch 3/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 11.17it/s, Loss=0.1432, Accuracy=0.9586]\n",
      "Epoch 4/20 [Train]: 100%|██████████| 235/235 [00:26<00:00,  8.71it/s, Loss=0.1454, Accuracy=0.9576]\n",
      "Epoch 4/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 11.44it/s, Loss=0.1233, Accuracy=0.9630]\n",
      "Epoch 5/20 [Train]: 100%|██████████| 235/235 [00:24<00:00,  9.51it/s, Loss=0.1264, Accuracy=0.9635]\n",
      "Epoch 5/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 12.89it/s, Loss=0.1074, Accuracy=0.9680]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▆▆▆▇▇▇▇▇▇▇██▇██████████████████████████</td></tr><tr><td>train/loss</td><td>██▅▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▆▇▇█</td></tr><tr><td>val/loss</td><td>█▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>4</td></tr><tr><td>total_steps</td><td>1175</td></tr><tr><td>train/accuracy</td><td>0.96875</td></tr><tr><td>train/loss</td><td>0.09536</td></tr><tr><td>val/accuracy</td><td>0.968</td></tr><tr><td>val/loss</td><td>0.10743</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-5e-04</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/mofct3j7' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/mofct3j7</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260112_132337-mofct3j7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Learning rate: 5e-04\n",
      "  Final train loss: 0.1264\n",
      "  Final val loss: 0.1074\n",
      "  Final val accuracy: 0.9680\n",
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=1e-03\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260112_132612-qmjsqcb2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/qmjsqcb2' target=\"_blank\">lr-1e-03</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/qmjsqcb2' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/qmjsqcb2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 235/235 [00:29<00:00,  8.00it/s, Loss=0.7549, Accuracy=0.7771]\n",
      "Epoch 1/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 12.45it/s, Loss=0.2295, Accuracy=0.9319]\n",
      "Epoch 2/20 [Train]: 100%|██████████| 235/235 [00:28<00:00,  8.15it/s, Loss=0.2114, Accuracy=0.9394]\n",
      "Epoch 2/20 [Validation]: 100%|██████████| 40/40 [00:02<00:00, 14.13it/s, Loss=0.1697, Accuracy=0.9486]\n",
      "Epoch 3/20 [Train]: 100%|██████████| 235/235 [00:27<00:00,  8.61it/s, Loss=0.1540, Accuracy=0.9565]\n",
      "Epoch 3/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 11.06it/s, Loss=0.1211, Accuracy=0.9633]\n",
      "Epoch 4/20 [Train]: 100%|██████████| 235/235 [00:26<00:00,  8.98it/s, Loss=0.1279, Accuracy=0.9636]\n",
      "Epoch 4/20 [Validation]: 100%|██████████| 40/40 [00:02<00:00, 15.08it/s, Loss=0.1005, Accuracy=0.9703]\n",
      "Epoch 5/20 [Train]: 100%|██████████| 235/235 [00:25<00:00,  9.26it/s, Loss=0.1109, Accuracy=0.9681]\n",
      "Epoch 5/20 [Validation]: 100%|██████████| 40/40 [00:02<00:00, 14.17it/s, Loss=0.0988, Accuracy=0.9712]\n",
      "Epoch 6/20 [Train]: 100%|██████████| 235/235 [00:29<00:00,  8.08it/s, Loss=0.0975, Accuracy=0.9722]\n",
      "Epoch 6/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 12.82it/s, Loss=0.0834, Accuracy=0.9753]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▃▄▆▆▇▇▇█▇▇▇▇▇█▇▇████▇██████████▇███████</td></tr><tr><td>train/loss</td><td>▆█▇█▇▅▅▄▅▆▄▅▆▄▃▄▃▂▃▃▃▄▃▂▃▃▃▃▂▁▃▂▁▁▃▂▁▂▂▃</td></tr><tr><td>val/accuracy</td><td>▁▄▆▇▇█</td></tr><tr><td>val/loss</td><td>█▅▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>5</td></tr><tr><td>total_steps</td><td>1410</td></tr><tr><td>train/accuracy</td><td>0.95833</td></tr><tr><td>train/loss</td><td>0.11665</td></tr><tr><td>val/accuracy</td><td>0.9753</td></tr><tr><td>val/loss</td><td>0.08345</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-1e-03</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/qmjsqcb2' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/qmjsqcb2</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260112_132612-qmjsqcb2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Learning rate: 1e-03\n",
      "  Final train loss: 0.0975\n",
      "  Final val loss: 0.0834\n",
      "  Final val accuracy: 0.9753\n",
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=5e-03\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260112_132919-aw4xwko2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/aw4xwko2' target=\"_blank\">lr-5e-03</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/aw4xwko2' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/aw4xwko2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 235/235 [00:28<00:00,  8.39it/s, Loss=0.3785, Accuracy=0.8902]\n",
      "Epoch 1/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 11.16it/s, Loss=0.1011, Accuracy=0.9691]\n",
      "Epoch 2/20 [Train]: 100%|██████████| 235/235 [00:27<00:00,  8.48it/s, Loss=0.0995, Accuracy=0.9726]\n",
      "Epoch 2/20 [Validation]: 100%|██████████| 40/40 [00:02<00:00, 13.73it/s, Loss=0.0738, Accuracy=0.9777]\n",
      "Epoch 3/20 [Train]: 100%|██████████| 235/235 [00:28<00:00,  8.33it/s, Loss=0.0714, Accuracy=0.9810]\n",
      "Epoch 3/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 11.53it/s, Loss=0.0511, Accuracy=0.9839]\n",
      "Epoch 4/20 [Train]: 100%|██████████| 235/235 [00:33<00:00,  7.03it/s, Loss=0.0578, Accuracy=0.9853]\n",
      "Epoch 4/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 10.83it/s, Loss=0.0550, Accuracy=0.9832]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▃▁▄▃▇▅▆█▆▇▇▇▇▇▇██▇▇▇██▇▆▇▆▇█▆▇▇▇▆██▇██▇▇</td></tr><tr><td>train/loss</td><td>█▅▆▅▃▃▃▃▂▂▂▁▂▂▂▁▁▂▁▂▁▂▂▁▁▂▂▁▁▂▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▅██</td></tr><tr><td>val/loss</td><td>█▄▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_epochs</td><td>3</td></tr><tr><td>total_steps</td><td>940</td></tr><tr><td>train/accuracy</td><td>1</td></tr><tr><td>train/loss</td><td>0.00817</td></tr><tr><td>val/accuracy</td><td>0.9832</td></tr><tr><td>val/loss</td><td>0.055</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr-5e-03</strong> at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/aw4xwko2' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/aw4xwko2</a><br> View project at: <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260112_132919-aw4xwko2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run completed:\n",
      "  Learning rate: 5e-03\n",
      "  Final train loss: 0.0578\n",
      "  Final val loss: 0.0550\n",
      "  Final val accuracy: 0.9832\n",
      "\n",
      "============================================================\n",
      "Starting run with learning_rate=1e-02\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/wandb/run-20260112_133132-17gzrx11</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/17gzrx11' target=\"_blank\">lr-1e-02</a></strong> to <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arekpaterak/torch-batteries-integration/runs/17gzrx11' target=\"_blank\">https://wandb.ai/arekpaterak/torch-batteries-integration/runs/17gzrx11</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 235/235 [00:26<00:00,  8.77it/s, Loss=0.4187, Accuracy=0.8694]\n",
      "Epoch 1/20 [Validation]: 100%|██████████| 40/40 [00:03<00:00, 13.21it/s, Loss=0.1233, Accuracy=0.9617]\n",
      "Epoch 2/20 [Train]:  68%|██████▊   | 159/235 [00:18<00:09,  7.63it/s, Loss=0.1078, Accuracy=0.9700]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     22\u001b[39m callbacks = [\n\u001b[32m     23\u001b[39m     ExperimentTrackingCallback(\n\u001b[32m     24\u001b[39m         tracker=tracker,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     )\n\u001b[32m     38\u001b[39m ]\n\u001b[32m     40\u001b[39m battery = Battery(\n\u001b[32m     41\u001b[39m     model=model,\n\u001b[32m     42\u001b[39m     optimizer=optimizer,\n\u001b[32m     43\u001b[39m     metrics=metrics,\n\u001b[32m     44\u001b[39m     callbacks=callbacks,\n\u001b[32m     45\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m result = \u001b[43mbattery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m results.append({\n\u001b[32m     54\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: lr,\n\u001b[32m     55\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m: result[\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m],\n\u001b[32m     56\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m: result[\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m],\n\u001b[32m     57\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m: result[\u001b[33m\"\u001b[39m\u001b[33mval_metrics\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m],\n\u001b[32m     58\u001b[39m })\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRun completed:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/src/torch_batteries/trainer/core.py:194\u001b[39m, in \u001b[36mBattery.train\u001b[39m\u001b[34m(self, train_loader, val_loader, epochs, verbose)\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    192\u001b[39m progress.start_epoch(epoch)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m train_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m].append(train_metrics[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m train_metrics.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/src/torch_batteries/trainer/core.py:299\u001b[39m, in \u001b[36mBattery._train_epoch\u001b[39m\u001b[34m(self, dataloader, progress, epoch)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer.zero_grad()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m    291\u001b[39m step_context: EventContext = {\n\u001b[32m    292\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbattery\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    293\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    297\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m: epoch,\n\u001b[32m    298\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTRAIN_STEP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m# Handle flexible return: either loss or (loss, metrics_dict)\u001b[39;00m\n\u001b[32m    302\u001b[39m step_metrics = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/src/torch_batteries/events/handler.py:153\u001b[39m, in \u001b[36mEventHandler.call\u001b[39m\u001b[34m(self, event, *args, **kwargs)\u001b[39m\n\u001b[32m    150\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCalling handler for event \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, event.value)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mNo handler found for event \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, event.value)\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mMNISTNet.training_step\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;129m@charge\u001b[39m(Event.TRAIN_STEP)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, context: EventContext):\n\u001b[32m     28\u001b[39m     x, y = context[\u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.cross_entropy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mMNISTNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/modules/activation.py:144\u001b[39m, in \u001b[36mReLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    141\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/torch/nn/functional.py:1697\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1695\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1697\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x7f847b3f7df0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f84b06b2810, execution_count=14 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7f84bf6bf9d0, raw_cell=\"results = []\n",
      "\n",
      "for lr in learning_rates:\n",
      "    print(..\" transformed_cell=\"results = []\n",
      "\n",
      "for lr in learning_rates:\n",
      "    print(..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu/home/arkadiusz/coding/university/isi2/torch-batteries/notebooks/lr_sweep_early_stopping.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "Connection lost",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionResetError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_init.py:604\u001b[39m, in \u001b[36m_WandbInit._post_run_cell_hook\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33mresuming backend\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface.py:811\u001b[39m, in \u001b[36mInterfaceBase.publish_resume\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    810\u001b[39m     resume = pb.ResumeRequest()\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[39m, in \u001b[36mInterfaceShared._publish_resume\u001b[39m\u001b[34m(self, resume)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb.ResumeRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    333\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(resume=resume)\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[39m, in \u001b[36mInterfaceSock._publish\u001b[39m\u001b[34m(self, record, nowait)\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncer.run_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m._client.publish(request))\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_asyncer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[39m, in \u001b[36mAsyncioManager.run\u001b[39m\u001b[34m(self, fn)\u001b[39m\n\u001b[32m    133\u001b[39m future = \u001b[38;5;28mself\u001b[39m._schedule(fn, daemon=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent.futures.CancelledError:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[39m, in \u001b[36mAsyncioManager._wrap\u001b[39m\u001b[34m(self, fn, daemon, name)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task := asyncio.current_task()):\n\u001b[32m    217\u001b[39m         task.set_name(name)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/university/isi2/torch-batteries/.venv/lib/python3.13/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/asyncio/streams.py:386\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    376\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    377\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol._drain_helper()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-linux-x86_64-gnu/lib/python3.13/asyncio/streams.py:166\u001b[39m, in \u001b[36mFlowControlMixin._drain_helper\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_drain_helper\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection_lost:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionResetError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mConnection lost\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._paused:\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mConnectionResetError\u001b[39m: Connection lost"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting run with learning_rate={lr:.0e}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    model = MNISTNet()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    run = Run(\n",
    "        name=f\"lr-{lr:.0e}\",\n",
    "        config={\n",
    "            \"learning_rate\": lr,\n",
    "            \"patience\": patience,\n",
    "        },\n",
    "        job_type=\"train\",\n",
    "    )\n",
    "    \n",
    "    tracker = WandbTracker(entity=wandb_entity)\n",
    "    \n",
    "    callbacks = [\n",
    "        ExperimentTrackingCallback(\n",
    "            tracker=tracker,\n",
    "            project=project,\n",
    "            experiment=experiment,\n",
    "            run=run,\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            stage=\"val\",\n",
    "            metric=\"loss\",\n",
    "            patience=patience,\n",
    "            min_delta=0.1,\n",
    "            mode=\"min\",\n",
    "            verbose=True,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    battery = Battery(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    result = battery.train(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=max_epochs,\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'train_loss': result[\"train_loss\"][-1],\n",
    "        'val_loss': result[\"val_loss\"][-1],\n",
    "        'val_accuracy': result[\"val_metrics\"]['accuracy'][-1],\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nRun completed:\")\n",
    "    print(f\"  Learning rate: {lr:.0e}\")\n",
    "    print(f\"  Final train loss: {result['train_loss'][-1]:.4f}\")\n",
    "    print(f\"  Final val loss: {result['val_loss'][-1]:.4f}\")\n",
    "    print(f\"  Final val accuracy: {result['val_metrics']['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a37fb",
   "metadata": {},
   "source": [
    "## 5. Summary of Results\n",
    "\n",
    "Quick overview of all runs to identify the best learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEARNING RATE SWEEP SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'LR':<12} {'Val Loss':<12} {'Val Acc':<12} {'Epochs':<12} {'Status'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "best_lr = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for r in results:\n",
    "    status = \"Early Stopped\" if r['epochs_trained'] < max_epochs else \"Completed\"\n",
    "    print(f\"{r['lr']:<12.0e} {r['val_loss']:<12.4f} {r['val_accuracy']:<12.4f} {r['epochs_trained']:<12} {status}\")\n",
    "    \n",
    "    if r['val_accuracy'] > best_accuracy:\n",
    "        best_accuracy = r['val_accuracy']\n",
    "        best_lr = r['lr']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest learning rate: {best_lr:.0e}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827df9cb",
   "metadata": {},
   "source": [
    "## 6. View Results in Weights & Biases\n",
    "\n",
    "After running the experiments, you can:\n",
    "\n",
    "1. **View the dashboard**: Go to your wandb project page\n",
    "2. **Compare runs**: See all runs grouped by experiment\n",
    "3. **Analyze metrics**: \n",
    "   - Training curves showing convergence speed\n",
    "   - Comparison of final accuracies across learning rates\n",
    "   - Early stopping events\n",
    "4. **Download artifacts**: Access saved model checkpoints\n",
    "\n",
    "**Key insights to look for**:\n",
    "- Which learning rates converged quickly?\n",
    "- Which learning rates were stopped early due to poor performance?\n",
    "- What's the optimal learning rate for this problem?\n",
    "- Trade-off between convergence speed and final accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-batteries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
